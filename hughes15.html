<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title><span>Reliable and Scalable Variational Inference for the Hierarchical Dirichlet Process</span> | AISTATS 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="{Reliable and Scalable Variational Inference for the Hierarchical Dirichlet Process}">

  <meta name="citation_author" content="Hughes, Michael">

  <meta name="citation_author" content="Kim, Dae Il">

  <meta name="citation_author" content="Sudderth, Erik">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="370">
<meta name="citation_lastpage" content="378">
<meta name="citation_pdf_url" content="hughes15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1><span>Reliable and Scalable Variational Inference for the Hierarchical Dirichlet Process</span></h1>

	<div id="authors">
	
		Michael Hughes,
	
		Dae Il Kim,
	
		Erik Sudderth
	<br />
	</div>
	<div id="info">
		Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,
		pp. 370â€“378, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We introduce a new variational inference objective for hierarchical Dirichlet process admixture models. Our approach provides novel and scalable algorithms for learning nonparametric topic models of text documents and Gaussian admixture models of image patches. Improving on the point estimates of topic probabilities used in previous work, we define full variational posteriors for all latent variables and optimize parameters via a novel surrogate likelihood bound. We show that this approach has crucial advantages for data-driven learning of the number of topics. Via merge and delete moves that remove redundant or irrelevant topics, we learn compact and interpretable models with less computation. Scaling to millions of documents is possible using stochastic or memoized variational updates.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="hughes15.pdf">Download PDF</a></li>
			
			<li><a href="hughes15-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
