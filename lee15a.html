<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title><span>Deeply-Supervised Nets</span> | AISTATS 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="{Deeply-Supervised Nets}">

  <meta name="citation_author" content="Lee, Chen-Yu">

  <meta name="citation_author" content="Xie, Saining">

  <meta name="citation_author" content="Gallagher, Patrick">

  <meta name="citation_author" content="Zhang, Zhengyou">

  <meta name="citation_author" content="Tu, Zhuowen">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="562">
<meta name="citation_lastpage" content="570">
<meta name="citation_pdf_url" content="lee15a.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1><span>Deeply-Supervised Nets</span></h1>

	<div id="authors">
	
		Chen-Yu Lee,
	
		Saining Xie,
	
		Patrick Gallagher,
	
		Zhengyou Zhang,
	
		Zhuowen Tu
	<br />
	</div>
	<div id="info">
		Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,
		pp. 562–570, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We propose deeply-supervised nets (DSN), a method that simultaneously minimizes classification error and improves the directness and transparency of the hidden layer learning process. We focus our attention on three aspects of traditional convolutional-neural-network-type (CNN-type) architectures: (1) transparency in the effect intermediate layers have on overall classification; (2) discriminativeness and robustness of learned features, especially in early layers; (3) training effectiveness in the face of “vanishing” gradients. To combat these issues, we introduce “companion” objective functions at each hidden layer, in addition to the overall objective function at the output layer (an integrated strategy distinct from layer-wise pre-training). We also analyze our algorithm using techniques extended from stochastic gradient methods. The advantages provided by our method are evident in our experimental results, showing state-of-the-art performance on MNIST, CIFAR-10, CIFAR-100, and SVHN.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="lee15a.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
