<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title><span>Online Ranking with Top-1 Feedback</span> | AISTATS 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="{Online Ranking with Top-1 Feedback}">

  <meta name="citation_author" content="Chaudhuri, Sougata">

  <meta name="citation_author" content="Tewari, Ambuj">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="129">
<meta name="citation_lastpage" content="137">
<meta name="citation_pdf_url" content="chaudhuri15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1><span>Online Ranking with Top-1 Feedback</span></h1>

	<div id="authors">
	
		Sougata Chaudhuri,
	
		Ambuj Tewari
	<br />
	</div>
	<div id="info">
		Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,
		pp. 129â€“137, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We consider a setting where a system learns to rank a fixed set of <span class="math">\(m\)</span> items. The goal is produce good item rankings for users with diverse interests who interact online with the system for <span class="math">\(T\)</span> rounds. We consider a novel top-<span class="math">\(1\)</span> feedback model: at the end of each round, the relevance score for only the top ranked object is revealed. However, the performance of the system is judged on the entire ranked list. We provide a comprehensive set of results regarding learnability under this challenging setting. For PairwiseLoss and DCG, two popular ranking measures, we prove that the minimax regret is <span class="math">\(\Theta(T^{2/3})\)</span>. Moreover, the minimax regret is achievable using an efficient strategy that only spends <span class="math">\(O(m \log m)\)</span> time per round. The same efficient strategy achieves <span class="math">\(O(T^{2/3})\)</span> regret for Precision@<span class="math">\(k\)</span>. Surprisingly, we show that for normalized versions of these ranking measures, i.e., AUC, NDCG &amp; MAP, no online ranking algorithm can have sublinear regret.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="chaudhuri15.pdf">Download PDF</a></li>
			
			<li><a href="chaudhuri15-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
