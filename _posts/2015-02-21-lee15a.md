---
title: Deeply-Supervised Nets
abstract: 'We propose deeply-supervised nets (DSN), a method that simultaneously minimizes
  classification error and improves the directness and transparency of the hidden
  layer learning process. We focus our attention on three aspects of traditional convolutional-neural-network-type
  (CNN-type) architectures:  (1) transparency in the effect intermediate layers have
  on overall classification;  (2) discriminativeness and robustness of learned features,
  especially in early layers;  (3) training effectiveness in the face of “vanishing”
  gradients.  To combat these issues, we introduce “companion” objective functions
  at each hidden layer, in addition to the overall objective function at the output
  layer (an integrated strategy distinct from layer-wise pre-training). We also analyze
  our algorithm using techniques extended from stochastic gradient methods. The advantages
  provided by our method are evident in our experimental results, showing state-of-the-art
  performance on MNIST, CIFAR-10, CIFAR-100, and SVHN.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lee15a
month: 0
tex_title: "{Deeply-Supervised Nets}"
firstpage: 562
lastpage: 570
page: 562-570
order: 562
cycles: false
author:
- given: Chen-Yu
  family: Lee
- given: Saining
  family: Xie
- given: Patrick
  family: Gallagher
- given: Zhengyou
  family: Zhang
- given: Zhuowen
  family: Tu
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/lee15a.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
