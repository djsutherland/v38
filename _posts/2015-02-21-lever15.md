---
supplementary: http://proceedings.mlr.press/v38/lever15-supp.pdf
title: Modelling Policies in MDPs in Reproducing Kernel Hilbert Space
abstract: We consider modelling policies for MDPs in (vector-valued) reproducing kernel
  Hilbert function spaces (RKHS). This enables us to work “non-parametrically” in
  a rich function class, and provides the ability to learn complex policies. We present
  a framework for performing gradient-based policy optimization in the RKHS, deriving
  the functional gradient of the return for our policy, which has a simple form and
  can be estimated efficiently. The policy representation naturally focuses on the
  relevant region of state space defined by the policy trajectories, and does not
  rely on a-priori defined basis points; this can be an advantage in high dimensions
  where suitable basis points may be difficult to define a-priori. The method is adaptive
  in the sense that the policy representation will naturally adapt to the complexity
  of the policy being modelled, which is achieved with standard efficient sparsification
  tools in an RKHS. We argue that finding a good kernel on states can be easier then
  remetrizing a high dimensional feature space. We demonstrate the approach on benchmark
  domains and a simulated quadrocopter navigation task.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lever15
month: 0
tex_title: "{Modelling Policies in MDPs in Reproducing Kernel Hilbert Space}"
firstpage: 590
lastpage: 598
page: 590-598
order: 590
cycles: false
author:
- given: Guy
  family: Lever
- given: Ronnie
  family: Stafford
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/lever15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
