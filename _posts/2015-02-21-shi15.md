---
title: Learning Where to  Sample in Structured Prediction
abstract: In structured prediction, most inference algorithms allocate a homogeneous
  amount of computation to all parts of the output, which can be wasteful when different
  parts vary widely in terms of difficulty. In this paper, we propose a heterogeneous
  approach that dynamically allocates computation to the different parts. Given a
  pre-trained model, we tune its inference algorithm (a sampler) to increase test-time
  throughput. The inference algorithm is parametrized by a meta-model and trained
  via reinforcement learning, where actions correspond to sampling candidate parts
  of the output, and rewards are log-likelihood improvements. The meta-model is based
  on a set of domain-general meta-features capturing the progress of the sampler.
  We test our approach on five datasets and show that it attains the same accuracy
  as Gibbs sampling but is 2 to 5 times faster.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: shi15
month: 0
tex_title: "{Learning Where to  Sample in Structured Prediction}"
firstpage: 875
lastpage: 884
page: 875-884
order: 875
cycles: false
author:
- given: Tianlin
  family: Shi
- given: Jacob
  family: Steinhardt
- given: Percy
  family: Liang
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/shi15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
