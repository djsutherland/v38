---
supplementary: Supplementary:mei15-supp.pdf
title: "{The Security of Latent Dirichlet Allocation}"
abstract: 'Latent Dirichlet allocation (LDA) is an increasingly popular tool for data
  analysis in many domains. If LDA output affects decision making (especially when
  money is involved), there is an incentive for attackers to compromise it. We ask
  the question: how can an attacker minimally poison the corpus so that LDA produces
  topics that the attacker wants the LDA user to see? Answering this question is important
  to characterize such attacks, and to develop defenses in the future. We give a novel
  bilevel optimization formulation to identify the optimal poisoning attack. We present
  an efficient solution (up to local optima) using descent method and implicit functions.
  We demonstrate poisoning attacks on LDA with extensive experiments, and discuss
  possible defenses.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mei15
month: 0
firstpage: 681
lastpage: 689
page: 681-689
sections: 
author:
- given: Shike
  family: Mei
- given: Xiaojin
  family: Zhu
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/mei15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
