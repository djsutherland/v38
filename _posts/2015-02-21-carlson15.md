---
supplementary: http://proceedings.mlr.press/v38/carlson15-supp.pdf
title: Stochastic Spectral Descent for Restricted Boltzmann Machines
abstract: Restricted Boltzmann Machines (RBMs) are widely used as building blocks
  for deep learning models. Learning typically proceeds by using stochastic gradient
  descent, and the gradients are estimated with sampling methods. However, the gradient
  estimation is a computational bottleneck, so better use of the gradients will speed
  up the descent algorithm. To this end, we first derive upper bounds on the RBM cost
  function, then show that descent methods can have natural ad- vantages by operating
  in the L∞and Shatten-∞norm. We introduce a new method called “Stochastic Spectral
  Descent” that updates parameters in the normed space. Empirical results show dramatic
  improvements over stochastic gradient descent, and have only have a fractional increase
  on the per-iteration cost.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: carlson15
month: 0
tex_title: "{Stochastic Spectral Descent for Restricted Boltzmann Machines}"
firstpage: 111
lastpage: 119
page: 111-119
order: 111
cycles: false
author:
- given: David
  family: Carlson
- given: Volkan
  family: Cevher
- given: Lawrence
  family: Carin
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/carlson15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
