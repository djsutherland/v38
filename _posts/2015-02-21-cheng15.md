---
supplementary: http://proceedings.mlr.press/v38/cheng15-supp.zip
title: Model Selection for Topic Models via Spectral Decomposition
abstract: Topic models have achieved significant successes in analyzing large-scale
  text corpus. In practical applications, we are always confronted with the challenge
  of model selection, i.e., how to appropriately set the number of topics.  Following
  the recent advances in topic models  via tensor decomposition, we make a first attempt
  to provide theoretical analysis on model selection in latent Dirichlet allocation.
  With mild conditions, we derive the upper bound and lower bound on the number of
  topics given a text collection of finite size. Experimental results demonstrate
  that our bounds are correct and tight. Furthermore, using Gaussian mixture model
  as an example, we show that our methodology can be easily generalized to model selection
  analysis in other latent models.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cheng15
month: 0
tex_title: "{Model Selection for Topic Models via Spectral Decomposition}"
firstpage: 183
lastpage: 191
page: 183-191
order: 183
cycles: false
author:
- given: Dehua
  family: Cheng
- given: Xinran
  family: He
- given: Yan
  family: Liu
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/cheng15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
