---
title: "{Direct Density-Derivative Estimation and Its Application in KL-Divergence
  Approximation}"
abstract: Estimation of density derivatives is a versatile tool in statistical data
  analysis. A naive approach is to first estimate the density and then compute its
  derivative.  However, such a two-step approach does not work well because a good
  density estimator does not necessarily mean a good density-derivative estimator.
  In this paper, we give a direct method to approximate the density derivative without
  estimating the density itself.  Our proposed estimator allows analytic and computationally
  efficient approximation of multi-dimensional high-order density derivatives, with
  the ability that all hyper-parameters can be chosen objectively by cross-validation.
  We further show that the proposed density-derivative estimator is useful in improving
  the accuracy of non-parametric KL-divergence estimation via metric learning. The
  practical superiority of the proposed method is experimentally demonstrated in change
  detection and feature selection.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sasaki15
month: 0
firstpage: 809
lastpage: 818
page: 809-818
sections: 
author:
- given: Hiroaki
  family: Sasaki
- given: Yung-Kyun
  family: Noh
- given: Masashi
  family: Sugiyama
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/sasaki15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
