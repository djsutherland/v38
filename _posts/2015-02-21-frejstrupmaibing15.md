---
title: "{Computational Complexity of Linear Large Margin Classification With Ramp
  Loss}"
abstract: Minimizing the binary classification error with a linear model leads to
  an NP-hard problem.  In practice, surrogate loss functions are used, in particular
  loss functions leading to large margin classification such as the hinge loss and
  the ramp loss. The intuitive large margin concept is theoretically supported by
  generalization bounds linking the expected classification error to the empirical
  margin error and the complexity of the considered hypotheses class. This article
  addresses the fundamental question about the computational complexity of determining
  whether there is a hypotheses class with a hypothesis such that the upper bound
  on the generalization error is below a certain value. Results of this type are important
  for model comparison and selection. This paper takes a first step and proves that
  minimizing a basic margin-bound is NP-hard when considering linear hypotheses and
  the rho-margin loss function, which generalizes  the ramp loss. This result directly
  implies the hardness of ramp loss minimization.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: frejstrupmaibing15
month: 0
firstpage: 259
lastpage: 267
page: 259-267
sections: 
author:
- given: SÃ¸ren
  family: Frejstrup Maibing
- given: Christian
  family: Igel
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/frejstrupmaibing15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
