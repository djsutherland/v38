---
supplementary: Supplementary:jampani15-supp.pdf
title: Consensus Message Passing for Layered Graphical Models
abstract: Generative models provide a powerful framework for probabilistic reasoning.
  However, in many domains their use has been hampered by the practical difficulties
  of inference. This is particularly the case in computer vision, where models of
  the imaging process tend to be large, loopy and layered. For this reason bottom-up
  conditional models have traditionally dominated in such domains. We find that widely-used,
  general-purpose message passing inference algorithms such as Expectation Propagation
  (EP) and Variational Message Passing (VMP) fail on the simplest of vision models.
  With these models in mind, we introduce a modification to message passing that learns
  to exploit their layered structure by passing ’consensus’ messages that guide inference
  towards good solutions. Experiments on a variety of problems show that the proposed
  technique leads to significantly more accurate inference results, not only when
  compared to standard EP and VMP, but also when compared to competitive bottom-up
  conditional models.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: jampani15
month: 0
tex_title: "{Consensus Message Passing for Layered Graphical Models}"
firstpage: 425
lastpage: 433
page: 425-433
sections: 
author:
- given: Varun
  family: Jampani
- given: S. M. Ali
  family: Eslami
- given: Daniel
  family: Tarlow
- given: Pushmeet
  family: Kohli
- given: John
  family: Winn
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/jampani15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
