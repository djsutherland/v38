---
supplementary: http://proceedings.mlr.press/v38/jadbabaie15-supp.pdf
title: 'Online Optimization : Competing with Dynamic Comparators'
abstract: Recent literature on online learning has focused on developing adaptive
  algorithms that take advantage of a regularity of the sequence of observations,
  yet retain worst-case performance guarantees. A complementary direction is to develop
  prediction methods that perform well against complex benchmarks. In this paper,
  we address these two directions together. We present a fully adaptive method that
  competes with dynamic benchmarks in which regret guarantee scales with regularity
  of the sequence of cost functions and comparators. Notably, the regret bound adapts
  to the smaller complexity measure in the problem environment. Finally, we apply
  our results to drifting zero-sum, two-player games where both players achieve no
  regret guarantees against best sequences of actions in hindsight.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: jadbabaie15
month: 0
tex_title: "{Online Optimization : Competing with Dynamic Comparators}"
firstpage: 398
lastpage: 406
page: 398-406
order: 398
cycles: false
author:
- given: Ali
  family: Jadbabaie
- given: Alexander
  family: Rakhlin
- given: Shahin
  family: Shahrampour
- given: Karthik
  family: Sridharan
date: 2015-02-21
address: San Diego, California, USA
publisher: PMLR
container-title: Proceedings of the Eighteenth International Conference on Artificial
  Intelligence and Statistics
volume: '38'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 2
  - 21
pdf: http://proceedings.mlr.press/v38/jadbabaie15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
