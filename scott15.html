<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title><span>A Rate of Convergence for Mixture Proportion Estimation, with Application to Learning from Noisy Labels</span> | AISTATS 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="{A Rate of Convergence for Mixture Proportion Estimation, with  Application to Learning from Noisy Labels}">

  <meta name="citation_author" content="Scott, Clayton">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="838">
<meta name="citation_lastpage" content="846">
<meta name="citation_pdf_url" content="scott15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1><span>A Rate of Convergence for Mixture Proportion Estimation, with Application to Learning from Noisy Labels</span></h1>

	<div id="authors">
	
		Clayton Scott
	<br />
	</div>
	<div id="info">
		Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,
		pp. 838–846, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Mixture proportion estimation (MPE) is a fundamental tool for solving a number of weakly supervised learning problems – supervised learning problems where label information is noisy or missing. Previous work on MPE has established a universally consistent estimator. In this work we establish a rate of convergence for mixture proportion estimation under an appropriate distributional assumption, and argue that this rate of convergence is useful for analyzing weakly supervised learning algorithms that build on MPE. To illustrate this idea, we examine an algorithm for classification in the presence of noisy labels based on surrogate risk minimization, and show that the rate of convergence for MPE enables proof of the algorithm’s consistency. Finally, we provide a practical implementation of mixture proportion estimation and demonstrate its efficacy in classification with noisy labels.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="scott15.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
