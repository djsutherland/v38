<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title><span>Learning of Non-Parametric Control Policies with High-Dimensional State Features</span> | AISTATS 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="{Learning of Non-Parametric Control Policies with High-Dimensional State Features}">

  <meta name="citation_author" content="Van Hoof, Herke">

  <meta name="citation_author" content="Peters, Jan">

  <meta name="citation_author" content="Neumann, Gerhard">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="995">
<meta name="citation_lastpage" content="1003">
<meta name="citation_pdf_url" content="vanhoof15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1><span>Learning of Non-Parametric Control Policies with High-Dimensional State Features</span></h1>

	<div id="authors">
	
		Herke Van Hoof,
	
		Jan Peters,
	
		Gerhard Neumann
	<br />
	</div>
	<div id="info">
		Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,
		pp. 995â€“1003, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Learning complex control policies from high-dimensional sensory input is a challenge for reinforcement learning algorithms. Kernel methods that approximate values functions or transition models can address this problem. Yet, many current approaches rely on instable greedy maximization. In this paper, we develop a policy search algorithm that integrates robust policy updates and kernel embeddings. Our method can learn non-parametric control policies for infinite horizon continuous MDPs with high-dimensional sensory representations. We show that our method outperforms related approaches, and that our algorithm can learn an underpowered swing-up task task directly from high-dimensional image data.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="vanhoof15.pdf">Download PDF</a></li>
			
			<li><a href="vanhoof15-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
